\section{論文の長所及び短所}

この論文の長所としては以下のような3つが挙げられる．

\begin{itemize}
  \item 画像の一致性を学習可能である．
  \item 画像の一致性を予測する精度として過去のものと比べ最も良い結果を示した．
  \item Hard Negative MiningやTransformer Networkなど学習方法において有益な知見を残した．
\end{itemize}

一つ目の学習可能であることはデータセットにおける一致性の意味によって
学習モデルを変化することができるということである．
先の論文の選択理由の節で述べたように，一致性はにも，
物体クラスの一致やクラスではなく物体としての同一性(インスタンス)も含めた一致が考えられ，
それらは適用シーンやデータセットに依って異なる．
先の例において，
物体認識や物体セグメンテーションではクラスにおける同一性のみで学習される必要があり，
物体検出やトラッキングにおいてはインスタンスとしての同一性の学習が求められる．

二つ目は実験によって示されたものであるが，KITTI，PASCAL, CUB-2011の3つのデータセットにおいて
提案モデルであるUniversal Correspondence Network(UCN)の有効性を精度の向上によって示しており，
モデルの有効性が説得力のある形で示されている．

三つ目は画像マッチング以外に対しても学習手法として有益な知見を多く含んでいることである．
一つは誤りの大きいものをロスとして優先的に取るHard Negative Miningの有効性で，
学習を高速化しかつ最終的な精度も向上していることを実験で示している．
もうひとつはConvolutional Spatial Transformer Networkの有効性で，
パッチにおける特徴量の正規化の手法として有効であることを実験で示しており，
他の畳み込みネットワークを用いた画像特徴抽出を行う手法への応用が期待される．

一方で短所としては，以下の3つが挙げられる．

\begin{itemize}
  \item 異なる一致性に対しては別々に学習する必要がある．
  \item 密な一致性に関して提案手法の一部の有効性を示していない．
  \item 一致性における大域的な最適化を含めた結果を示していない．
\end{itemize}

一つ目は，学習可能である一方で異なる一致性を含めたモデルとして学習可能
であることを示すまでには至らなかったということである．
理想的には，同じクラスだがインスタンスの異なる画像を二枚いれたときはクラスに関して一致性を予測し，
同じインスタンスが映っている画像を二枚いれたときにはインスタンスに関して一致性を予測する
ということが期待される．PASCALデータセットでの結果は前者であり，
KITTIデータセットでの結果は後者であると考えられるが，それらを織り交ぜた実験の結果は
示されていない．

二つ目は，密な一致性を出力できることを論文では利点として上げていたが，
密な一致性の出力においては提案したネットワークであるConvolutional Spatial Transformer Network
の有効性を示せなかったことである．
論文中では，データセットの小ささによって過学習してしまったのでは
ないかという考察にとどまっている．

三つ目は，一致性における大域的な最適化を行った精度を示していないことで，
実験においては過去のモデルと比較して，過去のモデルでは画像における大域的な
最適化を行って精度を計算しているのに対して提案モデルではそれを行っておらず，
それによってどれほどの精度が出るのかを示していない．
今後の研究における引用を考えると，最も良い結果が示されている方がより有益である
と考えられる．
